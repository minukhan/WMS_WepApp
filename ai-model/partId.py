import pandas as pd
import tensorflow as tf
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
import requests
import json
from datetime import datetime, timedelta
import certifi
from sklearn.model_selection import train_test_split
from dotenv import load_dotenv
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score



# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
SERVICE_KEY = os.getenv("SERVICE_KEY")

if not SERVICE_KEY:
    raise ValueError("ğŸš¨ SERVICE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# Load data
sales_data = pd.read_csv('mock_sales_data.csv')
exchange_data = pd.read_csv('exchange.csv')
hyundai_car_stock_data = pd.read_csv('hyundai_stock_monthly_avg.csv')

# Data preprocessing
sales_data['date'] = pd.to_datetime(sales_data['date'], format='%Y-%m')
exchange_data['date'] = pd.to_datetime(exchange_data[['Year', 'Month']].assign(Day=1))
hyundai_car_stock_data['date'] = pd.to_datetime(hyundai_car_stock_data[['Year', 'Month']].assign(Day=1))

# Merge data
sales_data = sales_data.merge(exchange_data, how='left', on='date')
sales_data = sales_data.merge(hyundai_car_stock_data, how='left', on='date')
sales_data.ffill(inplace=True)

# Create features and labels
sales_data['month'] = sales_data['date'].dt.month
sales_data['year'] = sales_data['date'].dt.year

# 1. ë¶€í’ˆë³„ ë°ì´í„°ë¡œ ë‚˜ëˆ„ê¸°
part_models = {}

for part_id in sales_data['part_id'].unique()[:5]:
    part_data = sales_data[sales_data['part_id'] == part_id]

    # Create features and labels
    X_part = part_data[['month', 'year', 'Exchange_rate', 'sales_quantity', 'Hyundai_Month_Stock_Average']]
    y_part = part_data['sales_quantity'].shift(-1).dropna()
    X_part = X_part[:-1]  # Remove the last row to align with y_part

    # Normalize data
    X_mean, X_std = X_part.mean(), X_part.std()
    X_part_normalized = (X_part - X_mean) / X_std
    y_mean, y_std = y_part.mean(), y_part.std()
    y_part_normalized = (y_part - y_mean) / y_std


    # TensorFlow model (ë¶€í’ˆë³„ë¡œ ëª¨ë¸ì„ í•™ìŠµ)
    model_part = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(X_part_normalized.shape[1],)),
        tf.keras.layers.Dense(16, activation='relu'),
        tf.keras.layers.Dense(8, activation='relu'),
        tf.keras.layers.Dense(1)
    ])

    model_part.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])

    # Train-test split
    X_train, X_val, y_train, y_val = train_test_split(X_part_normalized, y_part_normalized, test_size=0.2,
                                                      random_state=42)

    model_part.fit(X_train, y_train, epochs=30, batch_size=10, validation_data=(X_val, y_val), verbose=0)

    # ë¶€í’ˆë³„ ëª¨ë¸ ì €ì¥
    part_models[part_id] = {
        'model': model_part,
        'X_mean': X_mean,
        'X_std': X_std,
        'y_mean': y_mean,
        'y_std': y_std
    }

    print("í•™ìŠµ ì™„ë£Œ :", part_id)

# ğŸ”¹ ì˜ˆì¸¡ ìˆ˜í–‰ ë° ì„±ëŠ¥ í‰ê°€
for part_id in part_models:
    # ë¶€í’ˆë³„ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    part_model_info = part_models[part_id]
    model = part_model_info['model']
    X_mean = part_model_info['X_mean']
    X_std = part_model_info['X_std']
    y_mean = part_model_info['y_mean']
    y_std = part_model_info['y_std']

    # ë¶€í’ˆë³„ ë°ì´í„° ì¤€ë¹„
    part_data = sales_data[sales_data['part_id'] == part_id]
    X_part = part_data[['month', 'year', 'Exchange_rate', 'sales_quantity', 'Hyundai_Month_Stock_Average']]
    y_part = part_data['sales_quantity'].shift(-1).dropna()
    X_part = X_part[:-1]  # Remove the last row to align with y_part

    # Normalize data
    X_part_normalized = (X_part - X_mean) / X_std
    y_part_normalized = (y_part - y_mean) / y_std

    # ì˜ˆì¸¡ ìˆ˜í–‰
    predictions_normalized = model.predict(X_part_normalized)
    predictions = predictions_normalized * y_std + y_mean

    # ì„±ëŠ¥ í‰ê°€
    mae = mean_absolute_error(y_part, predictions)
    mse = mean_squared_error(y_part, predictions)
    r2 = r2_score(y_part, predictions)

    # ì„±ëŠ¥ ì¶œë ¥
    print(f"ğŸ“Š {part_id} ë¶€í’ˆì˜ ì˜ˆì¸¡ ì„±ëŠ¥:")
    print(f"ğŸ“Š Mean Absolute Error (MAE): {mae:.2f}")
    print(f"ğŸ“Š Mean Squared Error (MSE): {mse:.2f}")
    print(f"ğŸ“Š R2 Score: {r2:.2f}\n")


# FastAPI app setup
app = FastAPI()


# API input model
class PredictRequest(BaseModel):
    part_id: str
    current_sales: int

def fetch_exchange_rate():
    response = requests.get("https://m.search.naver.com/p/csearch/content/qapirender.nhn?key=calculator&pkid=141&q=%ED%99%98%EC%9C%A8&where=m&u1=keb&u6=standardUnit&u7=0&u3=USD&u4=KRW&u8=down&u2=1")
    if response.status_code == 200:
        try:
            data = response.json()
            # Debug: Print the response to check the actual structure
            # print("API Response:", data)

            # Safely retrieve the exchange rate from the 'country' key
            if 'country' in data and len(data['country']) > 1:
                exchange_rate = float(data['country'][1]['value'].replace(",", ""))
                # print("ì‹¤ì‹œê°„ í™˜ìœ¨ (USD)",exchange_rate)
                return exchange_rate
            else:
                raise HTTPException(status_code=500, detail="Unexpected response structure")
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Error parsing exchange rate: {str(e)}")
    else:
        raise HTTPException(status_code=500, detail="Failed to fetch exchange rate")

# Fetch Hyundai stock price
def fetch_hyundai_stock_price():
    # ì €ì¥ëœ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ì„ ê°€ì ¸ì˜¤ê¸°
    if os.path.exists("last_update.txt"):
        print("ì£¼ì‹ ê°’ì´ ìˆìŠµë‹ˆë‹¤.")
        with open("last_update.txt", "r") as file:
            last_update = file.read().strip()
            last_update = datetime.strptime(last_update, '%Y-%m-%d')

        # í˜„ì¬ ë‚ ì§œê°€ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ë‚ ì§œì™€ ê°™ì€ì§€ í™•ì¸
        if datetime.now().date() == last_update.date():
            # ì´ë¯¸ ì˜¤ëŠ˜ ì£¼ì‹ ê°€ê²©ì„ ê°€ì ¸ì™”ìœ¼ë©´ ì €ì¥ëœ ê°’ ì‚¬ìš©
            with open("stock_price.json", "r") as file:
                stock_data = json.load(file)
                print("ì´ë¯¸ ìˆëŠ” ê°’ ì‚¬ìš©",stock_data["price"])
                return stock_data["price"]
    else:
        print("ì£¼ì‹ ê°’ì„ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.")
        last_update = datetime.min  # ì²˜ìŒ ì‹¤í–‰ ì‹œ ê¸°ë³¸ ë‚ ì§œ ì„¤ì •

    # ì£¼ì‹ ê°€ê²© ê°€ì ¸ì˜¤ê¸°
    for i in range(10):
        target_date = (datetime.now() - timedelta(days=i + 1)).strftime('%Y%m%d')
        params = {
            'serviceKey': SERVICE_KEY,
            'resultType': 'json',
            'numOfRows': '1',
            'pageNo': '1',
            'basDt': target_date,
            'likeSrtnCd': '005380'
        }

        response = requests.get(
            "http://apis.data.go.kr/1160100/service/GetStockSecuritiesInfoService/getStockPriceInfo", params=params,
            verify=certifi.where())

        if response.status_code == 200:
            data = response.json()
            items = data['response']['body']['items']['item']
            if items:
                # ì¢…ê°€ ì €ì¥
                stock_price = float(items[0]['clpr'])

                # ì˜¤ëŠ˜ì˜ ì£¼ì‹ ê°€ê²©ì„ stock_price.jsonì— ì €ì¥
                print("ì˜¤ëŠ˜ì˜ ì£¼ì‹ ê°€ê²©ì„ stock_price.jsonì— ì €ì¥",stock_price)
                with open("stock_price.json", "w") as file:
                    json.dump({"price": stock_price}, file)

                # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ì„ ê¸°ë¡
                print("ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ì„ ê¸°ë¡",datetime.now().strftime('%Y-%m-%d'))
                with open("last_update.txt", "w") as file:
                    file.write(datetime.now().strftime('%Y-%m-%d'))

                return stock_price
        else:
            raise HTTPException(status_code=500, detail="Failed to fetch stock price")

    # ì„¸ ë²ˆì˜ ë‚ ì§œì— ëŒ€í•´ ëª¨ë‘ ê°€ê²©ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ 404 ì—ëŸ¬ ë°œìƒ
    raise HTTPException(status_code=404, detail="Stock price not found for the past 10 days")

@app.post("/predict")
def predict_sales(request: PredictRequest):
    part_id = request.part_id

    if part_id not in part_models:
        raise HTTPException(status_code=404, detail="Part ID not found")

    # ë¶€í’ˆë³„ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    part_model_info = part_models[part_id]
    model = part_model_info['model']
    X_mean = part_model_info['X_mean']
    X_std = part_model_info['X_std']
    y_mean = part_model_info['y_mean']
    y_std = part_model_info['y_std']

    # Prepare input data
    current_exchange_rate = fetch_exchange_rate()  # í™˜ìœ¨ ê°€ì ¸ì˜¤ê¸°
    current_stock_price = fetch_hyundai_stock_price()  # ì£¼ì‹ ê°€ê²© ê°€ì ¸ì˜¤ê¸°
    current_date = pd.Timestamp.now()

    input_data = pd.DataFrame({
        'month': [current_date.month],
        'year': [current_date.year],
        'Exchange_rate': [current_exchange_rate],
        'sales_quantity': [request.current_sales],
        'Hyundai_Month_Stock_Average': [current_stock_price]
    })
    input_data = (input_data - X_mean) / X_std  # ë°ì´í„° ì •ê·œí™”

    # Predict sales using the specific part model
    predicted_sales = model.predict(input_data)[0][0]
    predicted_sales = predicted_sales * y_std + y_mean  # ì˜ˆì¸¡ ê²°ê³¼ ë³µì›

    return {
        'part_id': request.part_id,
        'current_month_sales': request.current_sales,
        'predicted_next_month_sales': max(10, int(predicted_sales)),
    }

